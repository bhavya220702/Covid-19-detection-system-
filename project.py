# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xMKK_RAd9tLZ_Bn_HtwMyCIlTX-ZNaZW
"""

! pip install kaggle
! mkdir ~/.kaggle

from google.colab import drive
drive.mount('/content/drive')

!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json

!pip install --upgrade --force-reinstall --no-deps torch
!pip install --upgrade --force-reinstall --no-deps torchvision
!pip install timm

import numpy as np 
import pandas as pd 
import os
import torch
import torchvision
from torchvision import datasets, transforms
from torch import nn, optim
from torch.nn import functional as F
from torch.utils.data import DataLoader, sampler, random_split
from torchvision import models
from tqdm import tqdm
import time
import copy
import timm
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import timm
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

ROOT_PATH = "/content/drive/MyDrive/Covid19-dataset/"

train_dir = os.path.join(ROOT_PATH, 'train')

train_covid_dir = os.path.join(train_dir, 'Covid')
train_normal_dir = os.path.join(train_dir, 'Normal')
train_pneumonia_dir = os.path.join(train_dir, 'Viral Pneumonia')

train_covid_fnames = os.listdir(train_covid_dir)
train_normal_fnames = os.listdir(train_normal_dir)
train_pneumonia_fnames = os.listdir(train_pneumonia_dir)

print(train_covid_fnames[:10])
print(train_normal_fnames[:10])
print(train_pneumonia_fnames[:10])

nrows = 6
ncols = 4

pic_index = 0 # Index for iterating over images

fig = plt.gcf()
fig.set_size_inches(ncols*4, nrows*4)

pic_index+=8

covid_img_path_list = [os.path.join(train_covid_dir, fname) 
                for fname in train_covid_fnames[ pic_index-8:pic_index] ]
print("covid_img_path_list", covid_img_path_list)


normal_img_list = [os.path.join(train_normal_dir, fname) 
                for fname in train_normal_fnames[ pic_index-8:pic_index]
               ]

pneumonia_img_list = [os.path.join(train_pneumonia_dir, fname) 
                for fname in train_pneumonia_fnames[ pic_index-8:pic_index]
               ]

for i, img_path in enumerate(covid_img_path_list+normal_img_list+pneumonia_img_list):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

def get_dataset_loader(data_path, batch_size=256, train=False):
  if train:
    transform = transforms.Compose([
      transforms.RandomHorizontalFlip(p=0.5),
      transforms.RandomVerticalFlip(p=0.5),
      transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), transforms.GaussianBlur(3)]), p=0.1),
      transforms.Resize(256),
      transforms.CenterCrop(224),
      transforms.ToTensor(),
      transforms.Normalize((0.485, 0.456, 0.466), (0.229, 0.224, 0.255)),
      transforms.RandomErasing(p=0.12, value='random')
    ])

    train_imgs = datasets.ImageFolder(os.path.join(ROOT_PATH, 'train/'), transform=transform)

    print(f"We have {len(train_imgs)} Training Images with {len(train_imgs.classes)} classes")

    len_train_images = int(len(train_imgs) * 0.78)
    
    len_validation_images = int(len(train_imgs) - len_train_images )

    train_dataset, validation_dataset = random_split(train_imgs, [len_train_images, len_validation_images] )

    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)

    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)

    return train_dataloader, validation_dataloader, len(train_dataset), len(validation_dataset)

  else:
    transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.466), (0.229, 0.224, 0.255)),
  ])
  
  test_imgs = datasets.ImageFolder(os.path.join(ROOT_PATH, 'test/'), transform=transform)
  
  print(f"We have {len(test_imgs)} Training Images with {len(test_imgs.classes)} classes")
  
  test_dataloader = DataLoader(test_imgs, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
  
  return test_dataloader, len(test_imgs)

class_categories = datasets.ImageFolder(os.path.join(ROOT_PATH, 'train/')).classes
# ['Covid', 'Normal', 'Viral Pneumonia']
num_classes = len(class_categories)
num_classes

train_data = datasets.ImageFolder(os.path.join(ROOT_PATH, 'train/'))
train_data[2][0]

BATCH_SIZE = 32

(train_dataloader, validation_dataloader, len_train_dataloader, len_validation_dataloader) = get_dataset_loader(ROOT_PATH, batch_size=BATCH_SIZE, train=True)

(test_dataloader, len_test_dataloader) = get_dataset_loader(ROOT_PATH, batch_size=BATCH_SIZE, train=False)

train_dataloader.dataset

test_dataloader.dataset

print(len(train_dataloader))
print(len(validation_dataloader))
print(len(test_dataloader))
print(len_train_dataloader, len_validation_dataloader, len_test_dataloader )

dataloaders_dict = {
  'train': train_dataloader,
  'validation': validation_dataloader
}

dataset_sizes_dict = {
  'train':len_train_dataloader,
  'validation': len_validation_dataloader
}

for i, (inputs, labels) in enumerate(train_dataloader):
    print(inputs.shape, labels.shape)

train_loader_iterable = iter(train_dataloader)

images, labels = next(train_loader_iterable)

print('labels list is ', labels)

# Now for displaying I have to convert images to Numpy
images = images.numpy()
# plt.imshow(images[1][1]) # this is will display this image

# Plot images in batch along with corresponding labels.
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
  ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[] )
  plt.imshow(np.transpose(images[idx], (1,2,0)))
  # in above line transpose should convert
  # a `[channel, height, width]` tensor to a `[height, width, channel]` one.
  
  ax.set_title(class_categories[labels[idx]])

torch.backends.cudnn.benchmark = True

model = models.efficientnet_b0(pretrained=True)

print("model.classifier is => ", model.classifier)

""" model.classifier is =>  Sequential(
  (0): Dropout(p=0.2, inplace=True)
  (1): Linear(in_features=1280, out_features=1000, bias=True)
)
"""

for param in model.parameters():
  param.requires_grad = False
  
num_inputs = model.classifier[1].in_features


""" Now here is where I am adding additional layers to the pre-trained model.

for nn.Linear - note the following
in_features – size of each input sample
out_features – size of each output sample

"""


model.classifier = nn.Sequential(
  nn.Linear(num_inputs, 2048),
  nn.SiLU(), # Sigmoid Weighted Linear Unit
  nn.Dropout(0.2),
  # Note that the last layer is 2048 * Number of Classes
  # Reshape the final layer(s) to have the same number of outputs as the number of classes in the new dataset
  nn.Linear(2048, len(class_categories))
)

model = model.to(device)
print(model.classifier)

criterion = nn.CrossEntropyLoss(label_smoothing=0.11)
criterion = criterion.to(device)
optimizer = optim.AdamW(model.classifier.parameters(), lr=0.001 )

exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)
# Change the learning rate based on number of epochs
# Decays the learning rate of each parameter group by gamma every step_size epochs

training_history = {'accuracy': [], 'loss':[] }
validation_history = {'accuracy': [], 'loss': []}

def train(model, criterion, optimizer, scheduler, num_epochs=25):
  start_time = time.time()
  
  best_model_weights = copy.deepcopy(model.state_dict())
  best_accuracy = 0.0
  
  for epoch in range(num_epochs):
    print('Running epoch {}/{}'.format(epoch, num_epochs-1))
    print('-' * 10)
    

    for phase in ['train', 'validation']:
      if phase == 'train':
        model.train()
      else:
        model.eval()
      
      running_loss = 0.0
      running_corrects = 0
      
 
      for inputs, labels in tqdm(dataloaders_dict[phase]):
        inputs = inputs.to(device)
        labels = labels.to(device)
        
        
        optimizer.zero_grad()
        
        
        with torch.set_grad_enabled(phase == 'train'):
          predicted_outputs = model(inputs)          
          
          _, predictions = torch.max(predicted_outputs, 1)

          loss = criterion(predicted_outputs, labels)
          
          
          if phase == 'train':
            loss.backward()
            optimizer.step()
            
        
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(predictions == labels.data)
        
      if phase == 'train':
        scheduler.step()      
      
      epoch_loss = running_loss / dataset_sizes_dict[phase]
      epoch_accuracy = running_corrects.double() / dataset_sizes_dict[phase]
      
      
      
      
      if phase == 'train':
        training_history['loss'].append(epoch_loss)
        training_history['accuracy'].append(epoch_accuracy)
      elif phase == 'validation':
        validation_history['loss'].append(epoch_loss)
        validation_history['accuracy'].append(epoch_accuracy)
        

      if phase == 'validation' and epoch_accuracy > best_accuracy:
        best_accuracy = epoch_accuracy
        best_model_weights = copy.deepcopy(model.state_dict())
  
  time_elapsed = time.time() - start_time
  print('Training complete in {:.0f}m {:.0f}s'.format(
    time_elapsed // 60, time_elapsed % 60
  ))
  print('Best Validation Accuracy: {:4f}'.format(best_accuracy))
  
  model.load_state_dict(best_model_weights)
  return model

model_trained = train(model, criterion, optimizer, exp_lr_scheduler, num_epochs=150)

def evaluate(model):
  loss_on_test_dataset = 0.0
  correct_class = list(0. for i in range(len(class_categories)))
  total_correct_for_all_classes = list(0. for i in range(len(class_categories)))
  
  model.eval()
  
  for test_inputs, test_labels in tqdm(test_dataloader):
    # In local machine, below 2 Lines will NOT work if local GPU
    # itself or the GPU's Compute Capability is NOT compatible with PyTorch
    if torch.cuda.is_available():
      test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()
    
    with torch.no_grad():
      output_test = model(test_inputs)
      loss = criterion(output_test, test_labels)
    
    loss_on_test_dataset += loss.item() * test_inputs.size(0)
    _, pred_test = torch.max(output_test, 1)
    
    """ 
    Now compare predictions to true label
    
    view_as => View this tensor as the same size as other. 
    self.view_as(other) is equivalent to self.view(other.size()).   
    tensor.view_as(other) is equivalent to tensor.view(other.size())
    """
    correct_tensor = pred_test.eq(test_labels.view_as(pred_test))
    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())
    # Basically above will make sure if gpu is not available then we copy the tensor to cpu and convert it to numpy array.
    
    if len(test_labels) == BATCH_SIZE:
      for i in range(BATCH_SIZE):
        label = test_labels.data[i]
        correct_class[label] += correct[i].item() # updating corrects for each class object
        total_correct_for_all_classes[label] += 1 # updating corrects for total classes
        
  loss_on_test_dataset = loss_on_test_dataset/len(test_dataloader.dataset)
  print('Test Loss: {:.6f}\n'.format(loss_on_test_dataset))
  
  for i in range(len(class_categories)):
    if total_correct_for_all_classes[i] > 0:
      # Now print total Accuracy % and also number of corrects vs total number
      print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (
        class_categories[i], 100 * correct_class[i] / total_correct_for_all_classes[i],
        np.sum(correct_class[i]), np.sum(total_correct_for_all_classes[i])
      ))
    else:
      print('Test Accuracy of %5s: N/A (no training examples)' % (class_categories[i]))
  
  print('\n Test Accuracy (Overall): {:.4f} ({}/{})'.format(
    100 * np.sum(correct_class) / np.sum(total_correct_for_all_classes),
    np.sum(correct_class), np.sum(total_correct_for_all_classes)
  ))

evaluate(model_trained)